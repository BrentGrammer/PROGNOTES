# General terms

### Latency vs. Throughput

- Latency: The time it takes for a unit of data to travel from one location to another.
- Throughput: How much work a computer can do in a given amount of time. A knaive way to increase throughput is to pay for increase in processing power.
  - You can increase throughput vertically (pay for more processing power) or horizontally (create more servers to handle lots of requests in parallel)
- Latency and Throughput are not correlated. Having high latency but processing that takes a long time with lower throughput means that the high latency can be canceled out.

### Example

- 10Gbps  is through put - the system can process/send 10 Gigabits per second.
- Latency would be how long it takes for a unit of data to go from end to end - i.e. usually less than a second or microseconds.
