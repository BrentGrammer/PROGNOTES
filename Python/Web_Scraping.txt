WEB SCRAPING

-requests module (third party module) can download the string of text of the webpage (the html as a string)

-use beaitfulsoup module to parse pages easily: $ pip install beautifulsoup4

Beautiful Soup example scraping prices from Amazon web page:

import bs4
import requests

# download page:
res = requests.get('https://www.amazon.com/Automate-Boring-Stuff-Python-Programming/dp/1593275994/ref=sr_1_1?ie=UTF8&qid=1547592668&sr=8-1&keywords=automate+the+boring+stuff+python')
res.raise_for_status()

# pass the text of downloaded page to beautiful soup (returns a beautiful Soup object)

soup = bs4.BeautifulSoup(res.text, 'html.parser')

# find elements in the web page downloaded with the select() method on the bs obj returned:
# you need to pass in the CSS selector path - go to web page, right click on element, and 'copy css selector path', then paste it here.

elements = soup.select('#buyNewSection > h5 > div > div.a-column.a-span8.a-text-right.a-span-last > div > span.a-size-medium.a-color-price.offer-price.a-text-normal')

# select() returns a list of elements that match the css selector path passed in.
# select the index of the element you want from the list and you can access content with .text()

el = elements[0].text  <--contains inner html content (included newlines, etc.)
el.strip() <-- gets rid of newlines, etc.

*** Add User-Agent so that amazon doesn't think the program is a bot. 
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',
    }
        headers = {'content-type': 'application/json'}
    Ex: r = requests.post(url, data=json.dumps(payload), headers=headers)

====================================

USING SELENIUM TO LOGIN AND CLICK LINKS ETC>

*Basically mostly you will use the builtin methods find_element_by_css_selector or find_elements_by_css_selector

- $ pip install selenium

**NOTE: To use this with Chrome, you need to download the Chrome driver:  https://sites.google.com/a/chromium.org/chromedriver/downloads
Then you have to pass in the path to the executable from the download and include the exe file in the path:
browser = webdriver.Chrome('C:\\Users\\brent\\Downloads\\chromedriver_win32\\chromedriver.exe')


from selenium import webdriver

browser = webdriver.Firefox()  # this launches a firefox browser.
## NOte: if this throws error, try this: browser = webdriver.Firefox(capabilities={"marionette":False})
or 
browser = webdriver.Chrome('C:\\Users\\brent\\Downloads\\chromedriver_win32\\chromedriver.exe'))


browser.get('https://brentmarquez.com')  # sends browser to the url

elem = browser.find_element_by_css_selector('body > div.main > div:nth-child(1) > ul:nth-child(18) > li:nth-child(1) > a')

elem.click() <-- simulates a click on the selected element.

## get a list of elements
elems = browser.find_elements_by_css_selector('p')  <--gets all paragraph elements and returns a list of them

## enter keypresses into a field:
# find the element:
inputElem = browser.find_element_by_css_selector('.search-input')
# use the send_keys method on the element:
inputElem.send_keys('text to input')
# use selenium submit() call to automatically find the submit call in the form of the element:
inputElem.submit()

## Browser actions with Selenium:
browser.back()
browser.forward()
browser.refresh()
browser.quit() <--closes browser

----

READ TEXT FROM PAGE WITH SELENIUM:

-Ispect the element and right click on it in dev tools and copy unique selector

elem = find_element_by_css_selector('unique selector here')
elem.text <---all elements have a text prop with the text content of the element

## Get text for the whole page:
elem = find_element_by_css_selector('html')
elem.text

















---------------------------------------

Other methods available in Selenium:
see: https://selenium-python.readthedocs.io/locating-elements.html
find_element_by_id
find_element_by_name
find_element_by_xpath
find_element_by_link_text
find_element_by_partial_link_text
find_element_by_tag_name
find_element_by_class_name
find_element_by_css_selector
find_elements_by_name
find_elements_by_xpath
find_elements_by_link_text
find_elements_by_partial_link_text
find_elements_by_tag_name
find_elements_by_class_name
find_elements_by_css_selector


