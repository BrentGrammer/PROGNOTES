# S3 Simple Storage

- inifitely scalable storage
- Public service (runs in public AWS Zone)
- Region based (possible to replicate across regions)
- Object storage system (not a file or block storage system)
  - Good for accessing the whole object (images, audio files, etc.)
  - Not block storage that you can mount as a drive into images etc.
  - Good for offloading data and storing it
  - usually used for input and output to AWS services (most services offer integration with S3)

## Use Cases

- backup and storage
- Disaster Recovery
- Archiving
- Hybrid Cloud Storage (extend from on premise)
- Application hosting
- Media hosting
- Data lakes and big data analytics
- Software delivery
- Static website hosting

### Objects: files stored in S3

- Two parts: a key and a value (key is like a file name, the value is the data)
- Have a key which is the full path: s3://my-bucket/myfile.txt
- key is composed of the prefix (directories with slashes) and the file name
- **MAX SIZE**: From 0 bytes to 5 TB
  - must use a multi-part upload to upload larger files
- Have Metadat and tags that can be referenced and a version ID
- Objects are not actual files - they are just objects with a key.

### Buckets:

- like directories for the files
- Must have **globally unique name** across all regions and all accounts
  - see [rules](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html?icmpid=docs_amazons3_console)
  - Must be between 3 and 63 chars
  - Must start with lowercase letter or number
    - CANNOT begin with `X` or `N`
  - can contain dots and dashes
  - bucket names can't be IP formatted i.e. 1.1.1.1
  - soft limit of 100 buckets in an account (not per region), hard limit of 1000 (using support requests) - remember this to structure a system with many users - use prefixes with one bucket instead of a bucket per user for example.
- Tied to a specific region! Data has a primary home region and does not leave that unless configured to.
- Has to be defined at the region level and assigned a region
- there is naming convention restrictions
- Blast Radius is region level. (large scale failures are confined to the region)
- Note: all objects are stored at the root level of a bucket (there is no file directory heirarchy)
  - you can still have keys that have prefixes in the key that can simulate nested folders

### Cleaning up buckets

- two steps: you need to empty the bucket (click empty in the console) and then delete it.

# S3 Security

- User Based
  - IAM Policies - which API calls are allowed for a specific IAM user
  - Use case - attach a IAM policy to a user to access a bucket (no bucket policy needed)
  - For EC2 Instances use a role that has access policy for S3 buckets attached to it
- Resource Based
  - Bucket Policies allow cross account access
  - Use case is Public Access - attach a bucket policy that allows public access
  - Use case is a user that is on another AWS account that needs access - use a bucket
    policy
  - can also use them to force encryption
- IAM principal can access an S3 Object if either the user IAM policy or bucket policy allows it.
  - \*There is no explicit DENY policy
- Encryption - use encryption keys for bucket contents

## Public Access

- When creating a bucket if you uncheck Block all access it does NOT make the bucket publically accessible, but will allow you to configure it for public access if desired. It is a fail safe that will override any configuration you make to make the bucket public.
- All objects and buckets are private by default (you need to authenticate first) unless configured otherwise.
  - Example if you open an object link from the console in a new tab you will get Access Denied because you're accessing it as an unauthenticated user in a new fresh tab.
  - You need to use the `Open` button in AWS S3 Console to open the file in the browser which will authenticate you.

### Setting up policy for public Access

- You need to uncheck all the block public access settings first
- Can use the policy generator in the GUI to generate a policy
- The ARN should end with a slash and the bucket directories or files
  - `<arn>/*`
- Useful for allowing accesses to websites hosted on S3

### Static Website Hosting

- Enable the static website option in properties for the S3 settings
- make sure block settings are disabled and policy for public access is setup.

# Versioning

- Can enable file versioning at the bucket level
- Same key overwrite will update the version
- Best practice is to version buckets
  - restore from unintended delete and rollback file versions. To restore a file note that you delete the delete marker for it
- Note: files not versioned before enabling it will have a version of "null"
  - suspending versioning does not delete previous versions
- Setup: Enable bucket versioning in the properties tab of aws console gui for s3 bucket. This will auto generate versions of files uploaded for that bucket

# Access Logs

- for audit purposes or data analytics
- Logs are enabled and then written to another S3 bucket
  - NOTE: you need to create a new bucket for logging!
  - In the console you need to find menyu to enable Server access logging
    - For target bucket, remember to add `s3://` before the bucket name. You can also add a `/logs` to the end of the path
- Can take an hour or two before logs start populating after enabling

# S3 Replication

- CRR - Cross Region Replication
  - Use cases: compliance, lower latency access for distant/dispersed users, replication across accounts
- SRR - Same Region Replication
  - Use Cases: log aggregation, live replication between prod and test accounts
- Replication is Asynchronous in the background
- **Must enable (object/bucket) versioning in source and destination/target buckets**
- Bucket replicas can be in different accounts
- Must enable IAM permissions so buckets can copy over files
- Setup: Go to source bucket in AWS console and to Management tab, then create a replication Rule
  - note that version ids are replicated as well for files

# S3 Storage

- Types
  - Amazon S3 Standard - General Purpose
    - 99.99% Availability
    - Used for frequently accessed data
    - Low latency high throughput
    - can sustain 2 concurrent facility failures
    - Use Cases: Big Data Analytics, mobile and gaming apps, content distribution
  - Standard-Infrequent Access (IA)
  - One Zone-Infrequent Access
    - less frequently accessed files but requres rapid access when needed
    - lower cost than Standard
    - S3 Standard IA: 99.9% available (less than standard), used for disaster recovery and backups
    - S3 One Zone IA: 99.5% available, used to store backup copieds of data you can recreate or on prem data. \*Data is lost if an AZ is destroyed
  - Glacier: Low cost cold storage - pay for storage and retrieval cost
    - Glacier Instant Retrieval: millisecond retrieval - good for data accessed once a quarter. Min storage duration of 90 days, good for backup with fast retrieval
    - Glacier Flexible Retrieval
      - Expedited - 1 to 5 minutes retrieval
      - Standard - 3-5 hours for retrieval
      - Bulk - 5-12 hours for retrieval. This is free cost retrieval
      - Min. storage is 90 days
    - Glacier Deep Archive: long term storage
      - standard is 12 hours retrival, bulk is 48 hour wait for retreival
      - min. storage duration is 180 days
  - Intelligent Tiering
    - Small monthly monitoring and auto-tiering fees
    - No retrieval charges
    - Moves objects autopmatically between access tiers based on usage
    - Tiers:
      - Frequent Access: default tier
      - Infrequent Access: objects not accessed for 30 days
      - Archive Instant Access: not accessed for 90 days
      - Archive access(optional tier): configurable from 90-700 days
      - Deep Archive access(optional tier): configurable from 180-700 days
- Can move between classes manually or with lifecycles

S3 Durability: 11 9's - 99.999999999% - with 10,000,000 objects a loss can incur once every 10,000 years. This is for all storage classes in S3

Availability:

- Depends on storage class

- Can create Lifecycle Rules to determine when and where to move objects between storage class tiers based on your settings.

# LOCKS

- S3 Object Lock
  - WORM - write once read many - blocks object from editing or deletion for a time
- Glacier Vault Lock
  - Locks policy from editing for a time
- Used for compliance or scenarios where you need to retain a file unmodified for some time. Not even admins can edit it.

# S3 Encryption

- No Encryption
- Server Side - encrypted on backend after upload
- Client Side - encrypts before uploading

# AWS Storage Gateway

- Hybrid cloud solution
- Bridge on prem to S3 on the cloud
- Types: Tape Gateway, Amazon S3 File Gateway, Amazon FSx file Gateway, and Volume Gateway
